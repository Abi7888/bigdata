Follow
https://spark.apache.org/docs/latest/ec2-scripts.html


**Spark setup commands**

export AWS_SECRET_ACCESS_KEY=YourKeyHere AWS_ACCESS_KEY_ID=YourIDHere


./spark-ec2 --key-pair=my_key --identity-file=/your/path/here/my_key.pem --region=us-east-1 launch my-spark-cluster


./bin/spark-shell --master local[2]

**Our Sample Program**

val data = 1 to 10000
val distData = sc.parallelize(data)
distData.filter(_ < 10).collect()

** shut down ** 

./spark-ec2 destroy my-spark-cluster

